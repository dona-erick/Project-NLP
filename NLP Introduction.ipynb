{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc21294a-52a8-4410-b02f-4bd5449536a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import nltk, re, os\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize, wordpunct_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, LancasterStemmer, PorterStemmer\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a850627-efa5-4346-997f-9fd2ede816df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f7fe6c-a212-4311-abf8-c930a2a0069f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“The world as we have created it is a process ...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>change, deep-thoughts, thinking, world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“It is our choices, Harry, that show what we t...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>abilities, choices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“There are only two ways to live your life. On...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>inspirational, life, live, miracle, miracles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>aliteracy, books, classic, humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>be-yourself, inspirational</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           Author  \\\n",
       "0  “The world as we have created it is a process ...  Albert Einstein   \n",
       "1  “It is our choices, Harry, that show what we t...     J.K. Rowling   \n",
       "2  “There are only two ways to live your life. On...  Albert Einstein   \n",
       "3  “The person, be it gentleman or lady, who has ...      Jane Austen   \n",
       "4  “Imperfection is beauty, madness is genius and...   Marilyn Monroe   \n",
       "\n",
       "                                           Tags  \n",
       "0        change, deep-thoughts, thinking, world  \n",
       "1                            abilities, choices  \n",
       "2  inspirational, life, live, miracle, miracles  \n",
       "3              aliteracy, books, classic, humor  \n",
       "4                    be-yourself, inspirational  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('analyse_textuelles.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a372c6c-f968-4710-9dad-c6fd457aca3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88164279-c78b-4c61-bd70-a9010ae87da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "285201b0-f563-41d2-bac5-8cab2f3631b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          change, deep-thoughts, thinking, world\n",
       "1                              abilities, choices\n",
       "2    inspirational, life, live, miracle, miracles\n",
       "3                aliteracy, books, classic, humor\n",
       "4                      be-yourself, inspirational\n",
       "5                       adulthood, success, value\n",
       "6                                      life, love\n",
       "7     edison, failure, inspirational, paraphrased\n",
       "8                 misattributed-eleanor-roosevelt\n",
       "9                          humor, obvious, simile\n",
       "Name: Tags, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef6313f1-0104-40c7-b9d1-be5762224734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "df['Tags'] = df['Tags'].apply(lambda x: text_lower(x))\n",
    "df['text'] = df['text'].apply(lambda x: text_lower(x))\n",
    "df['Author'] = df['Author'].apply(lambda x: text_lower(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "462fc2dc-f028-4fae-a355-582326d2abe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 9.54 µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“the world as we have created it is a process ...</td>\n",
       "      <td>albert einstein</td>\n",
       "      <td>change deepthoughts thinking world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“it is our choices harry that show what we tru...</td>\n",
       "      <td>jk rowling</td>\n",
       "      <td>abilities choices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“there are only two ways to live your life one...</td>\n",
       "      <td>albert einstein</td>\n",
       "      <td>inspirational life live miracle miracles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“the person be it gentleman or lady who has no...</td>\n",
       "      <td>jane austen</td>\n",
       "      <td>aliteracy books classic humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“imperfection is beauty madness is genius and ...</td>\n",
       "      <td>marilyn monroe</td>\n",
       "      <td>beyourself inspirational</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           Author  \\\n",
       "0  “the world as we have created it is a process ...  albert einstein   \n",
       "1  “it is our choices harry that show what we tru...       jk rowling   \n",
       "2  “there are only two ways to live your life one...  albert einstein   \n",
       "3  “the person be it gentleman or lady who has no...      jane austen   \n",
       "4  “imperfection is beauty madness is genius and ...   marilyn monroe   \n",
       "\n",
       "                                       Tags  \n",
       "0        change deepthoughts thinking world  \n",
       "1                         abilities choices  \n",
       "2  inspirational life live miracle miracles  \n",
       "3             aliteracy books classic humor  \n",
       "4                  beyourself inspirational  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## suppression des ponctuations et autres \n",
    "import time\n",
    "%time\n",
    "import string\n",
    "def clean_text(text):\n",
    "    #mettre tout le contenu du texte en miniscules\n",
    "    #text = text.lower()\n",
    "    #supprimer les ponctuations\n",
    "    text = re.sub(\"\\[.*?\\]\", '', text)\n",
    "    #supprimer les urls html, asc\n",
    "    text = re.sub(\"https?://\\S+|www\\.\\S+\", '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub(\"\\n\", '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "df['Tags'] = df['Tags'].apply(lambda x: clean_text(x))\n",
    "df['text'] = df['text'].apply(lambda x: clean_text(x))\n",
    "df['Author'] = df['Author'].apply(lambda x: clean_text(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a0282c8-9a56-4570-b5ad-2daa81d0579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##tokenizer\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "def token(text):\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "df['Tags'] = df['Tags'].apply(lambda x: token(x))\n",
    "df['text'] = df['text'].apply(lambda x: token(x))\n",
    "df['Author'] = df['Author'].apply(lambda x: token(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3b8faf7-9c6a-4071-ab8b-d5aca6e08c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[the, world, as, we, have, created, it, is, a,...</td>\n",
       "      <td>[albert, einstein]</td>\n",
       "      <td>[change, deepthoughts, thinking, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[it, is, our, choices, harry, that, show, what...</td>\n",
       "      <td>[jk, rowling]</td>\n",
       "      <td>[abilities, choices]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[there, are, only, two, ways, to, live, your, ...</td>\n",
       "      <td>[albert, einstein]</td>\n",
       "      <td>[inspirational, life, live, miracle, miracles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[the, person, be, it, gentleman, or, lady, who...</td>\n",
       "      <td>[jane, austen]</td>\n",
       "      <td>[aliteracy, books, classic, humor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[imperfection, is, beauty, madness, is, genius...</td>\n",
       "      <td>[marilyn, monroe]</td>\n",
       "      <td>[beyourself, inspirational]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              Author  \\\n",
       "0  [the, world, as, we, have, created, it, is, a,...  [albert, einstein]   \n",
       "1  [it, is, our, choices, harry, that, show, what...       [jk, rowling]   \n",
       "2  [there, are, only, two, ways, to, live, your, ...  [albert, einstein]   \n",
       "3  [the, person, be, it, gentleman, or, lady, who...      [jane, austen]   \n",
       "4  [imperfection, is, beauty, madness, is, genius...   [marilyn, monroe]   \n",
       "\n",
       "                                             Tags  \n",
       "0         [change, deepthoughts, thinking, world]  \n",
       "1                            [abilities, choices]  \n",
       "2  [inspirational, life, live, miracle, miracles]  \n",
       "3              [aliteracy, books, classic, humor]  \n",
       "4                     [beyourself, inspirational]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35d35b2c-7b00-4140-993a-ea9d15dd205a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[world, created, process, thinking, cannot, ch...</td>\n",
       "      <td>[albert, einstein]</td>\n",
       "      <td>[change, deepthoughts, thinking, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[choices, harry, show, truly, far, abilities]</td>\n",
       "      <td>[jk, rowling]</td>\n",
       "      <td>[abilities, choices]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[two, ways, live, life, one, though, nothing, ...</td>\n",
       "      <td>[albert, einstein]</td>\n",
       "      <td>[inspirational, life, live, miracle, miracles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[person, gentleman, lady, pleasure, good, nove...</td>\n",
       "      <td>[jane, austen]</td>\n",
       "      <td>[aliteracy, books, classic, humor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[imperfection, beauty, madness, genius, better...</td>\n",
       "      <td>[marilyn, monroe]</td>\n",
       "      <td>[beyourself, inspirational]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              Author  \\\n",
       "0  [world, created, process, thinking, cannot, ch...  [albert, einstein]   \n",
       "1      [choices, harry, show, truly, far, abilities]       [jk, rowling]   \n",
       "2  [two, ways, live, life, one, though, nothing, ...  [albert, einstein]   \n",
       "3  [person, gentleman, lady, pleasure, good, nove...      [jane, austen]   \n",
       "4  [imperfection, beauty, madness, genius, better...   [marilyn, monroe]   \n",
       "\n",
       "                                             Tags  \n",
       "0         [change, deepthoughts, thinking, world]  \n",
       "1                            [abilities, choices]  \n",
       "2  [inspirational, life, live, miracle, miracles]  \n",
       "3              [aliteracy, books, classic, humor]  \n",
       "4                     [beyourself, inspirational]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## stopwords\n",
    "def stop_words_text(text):\n",
    "    stop_word = set(stopwords.words('english'))\n",
    "    word_text = [word for word in text if word not in stop_word]\n",
    "    return word_text\n",
    "\n",
    "df['Tags'] = df['Tags'].apply(lambda x: stop_words_text(x))\n",
    "df['text'] = df['text'].apply(lambda x: stop_words_text(x))\n",
    "df['Author'] = df['Author'].apply(lambda x: stop_words_text(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d38fae45-08d1-42e0-aa41-8bcf7548a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Leammatization or racinisation or normalisation\n",
    "df_lema = df.copy()\n",
    "lema= WordNetLemmatizer()\n",
    "def lem_word(text):\n",
    "    return [lema.lemmatize(word) for word in text]\n",
    "\n",
    "\n",
    "df_lema['Tags'] = df_lema['Tags'].apply(lambda x: lem_word(x))\n",
    "df_lema['text'] = df_lema['text'].apply(lambda x: lem_word(x))\n",
    "df_lema['Author'] = df_lema['Author'].apply(lambda x: lem_word(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41ded26c-f0c1-47e6-b36e-19a25b2bf90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[world, created, process, thinking, cannot, ch...</td>\n",
       "      <td>[albert, einstein]</td>\n",
       "      <td>[change, deepthoughts, thinking, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[choice, harry, show, truly, far, ability]</td>\n",
       "      <td>[jk, rowling]</td>\n",
       "      <td>[ability, choice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[two, way, live, life, one, though, nothing, m...</td>\n",
       "      <td>[albert, einstein]</td>\n",
       "      <td>[inspirational, life, live, miracle, miracle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[person, gentleman, lady, pleasure, good, nove...</td>\n",
       "      <td>[jane, austen]</td>\n",
       "      <td>[aliteracy, book, classic, humor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[imperfection, beauty, madness, genius, better...</td>\n",
       "      <td>[marilyn, monroe]</td>\n",
       "      <td>[beyourself, inspirational]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              Author  \\\n",
       "0  [world, created, process, thinking, cannot, ch...  [albert, einstein]   \n",
       "1         [choice, harry, show, truly, far, ability]       [jk, rowling]   \n",
       "2  [two, way, live, life, one, though, nothing, m...  [albert, einstein]   \n",
       "3  [person, gentleman, lady, pleasure, good, nove...      [jane, austen]   \n",
       "4  [imperfection, beauty, madness, genius, better...   [marilyn, monroe]   \n",
       "\n",
       "                                            Tags  \n",
       "0        [change, deepthoughts, thinking, world]  \n",
       "1                              [ability, choice]  \n",
       "2  [inspirational, life, live, miracle, miracle]  \n",
       "3              [aliteracy, book, classic, humor]  \n",
       "4                    [beyourself, inspirational]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lema.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c06b51a-7dce-414d-b6af-3660497de57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[world, cre, process, think, cannot, chang, wi...</td>\n",
       "      <td>[albert, einstein]</td>\n",
       "      <td>[chang, deepthought, think, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[cho, harry, show, tru, far, abl]</td>\n",
       "      <td>[jk, rowl]</td>\n",
       "      <td>[abl, cho]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[two, way, liv, lif, on, though, noth, mirac, ...</td>\n",
       "      <td>[albert, einstein]</td>\n",
       "      <td>[inspir, lif, liv, mirac, mirac]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[person, gentlem, lady, pleas, good, novel, mu...</td>\n",
       "      <td>[jan, aust]</td>\n",
       "      <td>[alit, book, class, hum]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[imperfect, beauty, mad, geni, bet, absolv, ri...</td>\n",
       "      <td>[marilyn, monro]</td>\n",
       "      <td>[beyourself, inspir]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              Author  \\\n",
       "0  [world, cre, process, think, cannot, chang, wi...  [albert, einstein]   \n",
       "1                  [cho, harry, show, tru, far, abl]          [jk, rowl]   \n",
       "2  [two, way, liv, lif, on, though, noth, mirac, ...  [albert, einstein]   \n",
       "3  [person, gentlem, lady, pleas, good, novel, mu...         [jan, aust]   \n",
       "4  [imperfect, beauty, mad, geni, bet, absolv, ri...    [marilyn, monro]   \n",
       "\n",
       "                                 Tags  \n",
       "0  [chang, deepthought, think, world]  \n",
       "1                          [abl, cho]  \n",
       "2    [inspir, lif, liv, mirac, mirac]  \n",
       "3            [alit, book, class, hum]  \n",
       "4                [beyourself, inspir]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemer = LancasterStemmer()\n",
    "def stemm_word(text):\n",
    "    return [stemer.stem(i) for i in text]\n",
    "\n",
    "for col in df_lema.columns:\n",
    "    df_lema[col] = df_lema[col].apply(lambda x: stemm_word(x))\n",
    "df_lema.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c13cfd03-d952-4147-8971-f0e74e5c79df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[world, cre, process, think, cannot, chang, wi...</td>\n",
       "      <td>[albert, einstein]</td>\n",
       "      <td>[chang, deepthought, think, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[cho, harri, show, tru, far, abl]</td>\n",
       "      <td>[jk, rowl]</td>\n",
       "      <td>[abl, cho]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[two, way, liv, lif, on, though, noth, mirac, ...</td>\n",
       "      <td>[albert, einstein]</td>\n",
       "      <td>[inspir, lif, liv, mirac, mirac]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[person, gentlem, ladi, plea, good, novel, mus...</td>\n",
       "      <td>[jan, aust]</td>\n",
       "      <td>[alit, book, class, hum]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[imperfect, beauti, mad, geni, bet, absolv, ri...</td>\n",
       "      <td>[marilyn, monro]</td>\n",
       "      <td>[beyourself, inspir]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              Author  \\\n",
       "0  [world, cre, process, think, cannot, chang, wi...  [albert, einstein]   \n",
       "1                  [cho, harri, show, tru, far, abl]          [jk, rowl]   \n",
       "2  [two, way, liv, lif, on, though, noth, mirac, ...  [albert, einstein]   \n",
       "3  [person, gentlem, ladi, plea, good, novel, mus...         [jan, aust]   \n",
       "4  [imperfect, beauti, mad, geni, bet, absolv, ri...    [marilyn, monro]   \n",
       "\n",
       "                                 Tags  \n",
       "0  [chang, deepthought, think, world]  \n",
       "1                          [abl, cho]  \n",
       "2    [inspir, lif, liv, mirac, mirac]  \n",
       "3            [alit, book, class, hum]  \n",
       "4                [beyourself, inspir]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "def porter_word(text):\n",
    "    return [porter.stem(a) for a in text]\n",
    "\n",
    "for col in df_lema.columns:\n",
    "    df_lema[col] = df_lema[col].apply(lambda x: porter_word(x))\n",
    "\n",
    "df_lema.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d8401f9-0464-4cf3-bb33-a298a7977c22",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mbrown\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('brown')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/brown\u001b[0m\n\n  Searched in:\n    - '/home/einstein/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mbrown\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('brown')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/brown.zip/brown/\u001b[0m\n\n  Searched in:\n    - '/home/einstein/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 12\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m brown\n\u001b[1;32m      6\u001b[0m word_net_map \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m: wordnet\u001b[38;5;241m.\u001b[39mNOUN, \n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m: wordnet\u001b[38;5;241m.\u001b[39mVERB,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR\u001b[39m\u001b[38;5;124m\"\u001b[39m: wordnet\u001b[38;5;241m.\u001b[39mADV,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJ\u001b[39m\u001b[38;5;124m\"\u001b[39m: wordnet\u001b[38;5;241m.\u001b[39mADJ\n\u001b[1;32m     11\u001b[0m }\n\u001b[0;32m---> 12\u001b[0m train_sents \u001b[38;5;241m=\u001b[39m \u001b[43mbrown\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtagged_sents\u001b[49m(categories\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnews\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m t0 \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mDefaultTagger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m t1 \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mUnigramTagger(train_sents, backoff \u001b[38;5;241m=\u001b[39mt0)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mbrown\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('brown')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/brown\u001b[0m\n\n  Searched in:\n    - '/home/einstein/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "## POST tagging\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import brown\n",
    "\n",
    "word_net_map = {\n",
    "    \"N\": wordnet.NOUN, \n",
    "    \"V\": wordnet.VERB,\n",
    "    \"R\": wordnet.ADV,\n",
    "    \"J\": wordnet.ADJ\n",
    "}\n",
    "train_sents = brown.tagged_sents(categories= \"news\")\n",
    "t0 = nltk.DefaultTagger(\"NN\")\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff =t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff=t1)\n",
    "\n",
    "#def post_tag_wordnet(text, post_tag_type = 'post_tag'):\n",
    "    #pos_tagged_text = t2.tag(text)\n",
    "    \n",
    "    # map the pos tagging output with wordnet output \n",
    "    #pos_tagged_text = [(word, word_net_map.get(pos_tag[0])) if pos_tag[0] in word_net_map.keys() else (word, wordnet.NOUN) for (word, pos_tag) in pos_tagged_text ]\n",
    "    #return pos_tagged_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f82cd5-37f8-4644-ba20-3d3e70bfcca5",
   "metadata": {},
   "source": [
    "TEXT FEATURES EXTRACTION  ====== BAG OF WORDS / BAG OF N-GRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d64c93d7-dce2-4570-80c4-4022bf034744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "989f6772-2c39-49f1-b3e0-40774e8f9711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[world, created, process, thinking, cannot, ch...</td>\n",
       "      <td>[albert, einstein]</td>\n",
       "      <td>[change, deepthoughts, thinking, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[choices, harry, show, truly, far, abilities]</td>\n",
       "      <td>[jk, rowling]</td>\n",
       "      <td>[abilities, choices]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[two, ways, live, life, one, though, nothing, ...</td>\n",
       "      <td>[albert, einstein]</td>\n",
       "      <td>[inspirational, life, live, miracle, miracles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[person, gentleman, lady, pleasure, good, nove...</td>\n",
       "      <td>[jane, austen]</td>\n",
       "      <td>[aliteracy, books, classic, humor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[imperfection, beauty, madness, genius, better...</td>\n",
       "      <td>[marilyn, monroe]</td>\n",
       "      <td>[beyourself, inspirational]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              Author  \\\n",
       "0  [world, created, process, thinking, cannot, ch...  [albert, einstein]   \n",
       "1      [choices, harry, show, truly, far, abilities]       [jk, rowling]   \n",
       "2  [two, ways, live, life, one, though, nothing, ...  [albert, einstein]   \n",
       "3  [person, gentleman, lady, pleasure, good, nove...      [jane, austen]   \n",
       "4  [imperfection, beauty, madness, genius, better...   [marilyn, monroe]   \n",
       "\n",
       "                                             Tags  \n",
       "0         [change, deepthoughts, thinking, world]  \n",
       "1                            [abilities, choices]  \n",
       "2  [inspirational, life, live, miracle, miracles]  \n",
       "3              [aliteracy, books, classic, humor]  \n",
       "4                     [beyourself, inspirational]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10ab6276-2dcc-4014-9a8d-9e40acd36771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[world, cre, process, think, cannot, chang, wi...</td>\n",
       "      <td>[albert, einstein]</td>\n",
       "      <td>[chang, deepthought, think, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[cho, harry, show, tru, far, abl]</td>\n",
       "      <td>[jk, rowl]</td>\n",
       "      <td>[abl, cho]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[two, way, liv, lif, on, though, noth, mirac, ...</td>\n",
       "      <td>[albert, einstein]</td>\n",
       "      <td>[inspir, lif, liv, mirac, mirac]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[person, gentlem, lady, pleas, good, novel, mu...</td>\n",
       "      <td>[jan, aust]</td>\n",
       "      <td>[alit, book, class, hum]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[imperfect, beauty, mad, geni, bet, absolv, ri...</td>\n",
       "      <td>[marilyn, monro]</td>\n",
       "      <td>[beyourself, inspir]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              Author  \\\n",
       "0  [world, cre, process, think, cannot, chang, wi...  [albert, einstein]   \n",
       "1                  [cho, harry, show, tru, far, abl]          [jk, rowl]   \n",
       "2  [two, way, liv, lif, on, though, noth, mirac, ...  [albert, einstein]   \n",
       "3  [person, gentlem, lady, pleas, good, novel, mu...         [jan, aust]   \n",
       "4  [imperfect, beauty, mad, geni, bet, absolv, ri...    [marilyn, monro]   \n",
       "\n",
       "                                 Tags  \n",
       "0  [chang, deepthought, think, world]  \n",
       "1                          [abl, cho]  \n",
       "2    [inspir, lif, liv, mirac, mirac]  \n",
       "3            [alit, book, class, hum]  \n",
       "4                [beyourself, inspir]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lancaster = LancasterStemmer()\n",
    "def stemming(text):\n",
    "    return [lancaster.stem(word) for word in text]\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda x: stemming(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "534a0041-ec37-47b6-8be6-547cd263f35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[world, cre, process, think, cannot, chang, wi...</td>\n",
       "      <td>[albert, einstein]</td>\n",
       "      <td>[chang, deepthought, think, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[cho, harry, show, tru, far, abl]</td>\n",
       "      <td>[jk, rowl]</td>\n",
       "      <td>[abl, cho]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[two, way, liv, lif, on, though, noth, mirac, ...</td>\n",
       "      <td>[albert, einstein]</td>\n",
       "      <td>[inspir, lif, liv, mirac, mirac]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[person, gentlem, lady, plea, good, novel, mus...</td>\n",
       "      <td>[jan, aust]</td>\n",
       "      <td>[alit, book, class, hum]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[imperfect, beauty, mad, geni, bet, absolv, ri...</td>\n",
       "      <td>[marilyn, monro]</td>\n",
       "      <td>[beyourself, inspir]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              Author  \\\n",
       "0  [world, cre, process, think, cannot, chang, wi...  [albert, einstein]   \n",
       "1                  [cho, harry, show, tru, far, abl]          [jk, rowl]   \n",
       "2  [two, way, liv, lif, on, though, noth, mirac, ...  [albert, einstein]   \n",
       "3  [person, gentlem, lady, plea, good, novel, mus...         [jan, aust]   \n",
       "4  [imperfect, beauty, mad, geni, bet, absolv, ri...    [marilyn, monro]   \n",
       "\n",
       "                                 Tags  \n",
       "0  [chang, deepthought, think, world]  \n",
       "1                          [abl, cho]  \n",
       "2    [inspir, lif, liv, mirac, mirac]  \n",
       "3            [alit, book, class, hum]  \n",
       "4                [beyourself, inspir]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lematizer(text):\n",
    "\n",
    "    \"\"\" WITHOUT POST TAGING Lemmatization of racinisation or normalisation . We can use  Lancastemmer , PorterStemmer, SnowBallStemmer and \n",
    "    also WordNetLemmatizer  \"\"\"\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem  = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return lem\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda x: lematizer(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e32adca-eaea-4628-aa8c-f1900e728803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>world cre process think cannot chang without c...</td>\n",
       "      <td>albert einstein</td>\n",
       "      <td>chang deepthought think world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cho harry show tru far abl</td>\n",
       "      <td>jk rowl</td>\n",
       "      <td>abl cho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>two way liv lif on though noth mirac though ev...</td>\n",
       "      <td>albert einstein</td>\n",
       "      <td>inspir lif liv mirac mirac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>person gentlem lady plea good novel must intol...</td>\n",
       "      <td>jan aust</td>\n",
       "      <td>alit book class hum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imperfect beauty mad geni bet absolv ridic abs...</td>\n",
       "      <td>marilyn monro</td>\n",
       "      <td>beyourself inspir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           Author  \\\n",
       "0  world cre process think cannot chang without c...  albert einstein   \n",
       "1                         cho harry show tru far abl          jk rowl   \n",
       "2  two way liv lif on though noth mirac though ev...  albert einstein   \n",
       "3  person gentlem lady plea good novel must intol...         jan aust   \n",
       "4  imperfect beauty mad geni bet absolv ridic abs...    marilyn monro   \n",
       "\n",
       "                            Tags  \n",
       "0  chang deepthought think world  \n",
       "1                        abl cho  \n",
       "2     inspir lif liv mirac mirac  \n",
       "3            alit book class hum  \n",
       "4              beyourself inspir  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##combined theirs text\n",
    "def combine_text(list_of_text):\n",
    "    combined_text = ' '.join(list_of_text)\n",
    "    return combined_text\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda x: combine_text(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54913ac3-e4eb-4b97-995d-de3346d14342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def countor_vectorizer(data, ngram = 1, max_of_words = 100000):\n",
    "    count_vectorize = CountVectorizer(ngram_range=(ngram, ngram), max_features= max_of_words)\n",
    "    embedding = count_vectorize.fit_transform(data).toarray()\n",
    "    print(\"countvectorizer with\", str(np.array(embedding).shape[1]), \"features\")\n",
    "    return embedding, count_vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15bda9eb-77ed-4cec-81d8-2a2d9d7dd373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(embedding, feat, ngram, compared_sentence= 0):\n",
    "    print(ngram,\"bag-of-words: \")\n",
    "    print(feat.get_feature_names_out(), \"\\n\")\n",
    "    print(ngram,\"bag-of-feature: \")\n",
    "    print(test_count_1gram.vocabulary_, \"\\n\")\n",
    "    print(\"BoW matrix:\")\n",
    "    print(pd.DataFrame(embedding.transpose(), index = feat.get_feature_names_out()).head(), \"\\n\")\n",
    "    print(ngram,\"vector example:\")\n",
    "    print(df['text'][compared_sentence])\n",
    "    print(embedding[compared_sentence], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e626452f-7c4a-4988-946a-7929d4e9560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test corpus:  ['world cre process think cannot chang without chang think', 'cho harry show tru far abl', 'two way liv lif on though noth mirac though everyth mirac', 'person gentlem lady plea good novel must intol stupid', 'imperfect beauty mad geni bet absolv ridic absolv bor'] \n",
      "\n",
      "countvectorizer with 39 features\n",
      "Uni-gram bag-of-words: \n",
      "['abl' 'absolv' 'beauty' 'bet' 'bor' 'cannot' 'chang' 'cho' 'cre'\n",
      " 'everyth' 'far' 'geni' 'gentlem' 'good' 'harry' 'imperfect' 'intol'\n",
      " 'lady' 'lif' 'liv' 'mad' 'mirac' 'must' 'noth' 'novel' 'on' 'person'\n",
      " 'plea' 'process' 'ridic' 'show' 'stupid' 'think' 'though' 'tru' 'two'\n",
      " 'way' 'without' 'world'] \n",
      "\n",
      "Uni-gram bag-of-feature: \n",
      "{'world': 38, 'cre': 8, 'process': 28, 'think': 32, 'cannot': 5, 'chang': 6, 'without': 37, 'cho': 7, 'harry': 14, 'show': 30, 'tru': 34, 'far': 10, 'abl': 0, 'two': 35, 'way': 36, 'liv': 19, 'lif': 18, 'on': 25, 'though': 33, 'noth': 23, 'mirac': 21, 'everyth': 9, 'person': 26, 'gentlem': 12, 'lady': 17, 'plea': 27, 'good': 13, 'novel': 24, 'must': 22, 'intol': 16, 'stupid': 31, 'imperfect': 15, 'beauty': 2, 'mad': 20, 'geni': 11, 'bet': 3, 'absolv': 1, 'ridic': 29, 'bor': 4} \n",
      "\n",
      "BoW matrix:\n",
      "        0  1  2  3  4\n",
      "abl     0  1  0  0  0\n",
      "absolv  0  0  0  0  2\n",
      "beauty  0  0  0  0  1\n",
      "bet     0  0  0  0  1\n",
      "bor     0  0  0  0  1 \n",
      "\n",
      "Uni-gram vector example:\n",
      "world cre process think cannot chang without chang think\n",
      "[0 0 0 0 0 1 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 0 0 0 0\n",
      " 1 1] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corpus = df['text'][:5].tolist()\n",
    "print(\"The test corpus: \", test_corpus, \"\\n\")\n",
    "\n",
    "test_count_emb, test_count_1gram = countor_vectorizer(test_corpus, ngram=1)\n",
    "print_out(test_count_emb, test_count_1gram, ngram=\"Uni-gram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f8627aa-df39-4eec-bf13-05cdebcfe281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test corpus:  ['world cre process think cannot chang without chang think', 'cho harry show tru far abl', 'two way liv lif on though noth mirac though everyth mirac', 'person gentlem lady plea good novel must intol stupid', 'imperfect beauty mad geni bet absolv ridic absolv bor'] \n",
      "\n",
      "countvectorizer with 39 features\n",
      "bi-gram bag-of-words: \n",
      "['absolv bor' 'absolv ridic' 'beauty mad' 'bet absolv' 'cannot chang'\n",
      " 'chang think' 'chang without' 'cho harry' 'cre process' 'everyth mirac'\n",
      " 'far abl' 'geni bet' 'gentlem lady' 'good novel' 'harry show'\n",
      " 'imperfect beauty' 'intol stupid' 'lady plea' 'lif on' 'liv lif'\n",
      " 'mad geni' 'mirac though' 'must intol' 'noth mirac' 'novel must'\n",
      " 'on though' 'person gentlem' 'plea good' 'process think' 'ridic absolv'\n",
      " 'show tru' 'think cannot' 'though everyth' 'though noth' 'tru far'\n",
      " 'two way' 'way liv' 'without chang' 'world cre'] \n",
      "\n",
      "bi-gram bag-of-feature: \n",
      "{'world': 38, 'cre': 8, 'process': 28, 'think': 32, 'cannot': 5, 'chang': 6, 'without': 37, 'cho': 7, 'harry': 14, 'show': 30, 'tru': 34, 'far': 10, 'abl': 0, 'two': 35, 'way': 36, 'liv': 19, 'lif': 18, 'on': 25, 'though': 33, 'noth': 23, 'mirac': 21, 'everyth': 9, 'person': 26, 'gentlem': 12, 'lady': 17, 'plea': 27, 'good': 13, 'novel': 24, 'must': 22, 'intol': 16, 'stupid': 31, 'imperfect': 15, 'beauty': 2, 'mad': 20, 'geni': 11, 'bet': 3, 'absolv': 1, 'ridic': 29, 'bor': 4} \n",
      "\n",
      "BoW matrix:\n",
      "              0  1  2  3  4\n",
      "absolv bor    0  0  0  0  1\n",
      "absolv ridic  0  0  0  0  1\n",
      "beauty mad    0  0  0  0  1\n",
      "bet absolv    0  0  0  0  1\n",
      "cannot chang  1  0  0  0  0 \n",
      "\n",
      "bi-gram vector example:\n",
      "world cre process think cannot chang without chang think\n",
      "[0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 1 1] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corpus = df['text'][:5].tolist()\n",
    "print(\"The test corpus: \", test_corpus, \"\\n\")\n",
    "\n",
    "test_count2_emb, test_count_2gram = countor_vectorizer(test_corpus, ngram=2)\n",
    "print_out(test_count2_emb, test_count_2gram, ngram=\"bi-gram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b1184cf-d6a2-4187-a947-0e3e384202f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test corpus:  ['world cre process think cannot chang without chang think', 'cho harry show tru far abl', 'two way liv lif on though noth mirac though everyth mirac', 'person gentlem lady plea good novel must intol stupid', 'imperfect beauty mad geni bet absolv ridic absolv bor'] \n",
      "\n",
      "countvectorizer with 34 features\n",
      "Tri-gram bag-of-words: \n",
      "['absolv ridic absolv' 'beauty mad geni' 'bet absolv ridic'\n",
      " 'cannot chang without' 'chang without chang' 'cho harry show'\n",
      " 'cre process think' 'geni bet absolv' 'gentlem lady plea'\n",
      " 'good novel must' 'harry show tru' 'imperfect beauty mad'\n",
      " 'lady plea good' 'lif on though' 'liv lif on' 'mad geni bet'\n",
      " 'mirac though everyth' 'must intol stupid' 'noth mirac though'\n",
      " 'novel must intol' 'on though noth' 'person gentlem lady'\n",
      " 'plea good novel' 'process think cannot' 'ridic absolv bor'\n",
      " 'show tru far' 'think cannot chang' 'though everyth mirac'\n",
      " 'though noth mirac' 'tru far abl' 'two way liv' 'way liv lif'\n",
      " 'without chang think' 'world cre process'] \n",
      "\n",
      "Tri-gram bag-of-feature: \n",
      "{'world': 38, 'cre': 8, 'process': 28, 'think': 32, 'cannot': 5, 'chang': 6, 'without': 37, 'cho': 7, 'harry': 14, 'show': 30, 'tru': 34, 'far': 10, 'abl': 0, 'two': 35, 'way': 36, 'liv': 19, 'lif': 18, 'on': 25, 'though': 33, 'noth': 23, 'mirac': 21, 'everyth': 9, 'person': 26, 'gentlem': 12, 'lady': 17, 'plea': 27, 'good': 13, 'novel': 24, 'must': 22, 'intol': 16, 'stupid': 31, 'imperfect': 15, 'beauty': 2, 'mad': 20, 'geni': 11, 'bet': 3, 'absolv': 1, 'ridic': 29, 'bor': 4} \n",
      "\n",
      "BoW matrix:\n",
      "                      0  1  2  3  4\n",
      "absolv ridic absolv   0  0  0  0  1\n",
      "beauty mad geni       0  0  0  0  1\n",
      "bet absolv ridic      0  0  0  0  1\n",
      "cannot chang without  1  0  0  0  0\n",
      "chang without chang   1  0  0  0  0 \n",
      "\n",
      "Tri-gram vector example:\n",
      "world cre process think cannot chang without chang think\n",
      "[0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_corpus = df['text'][:5].tolist()\n",
    "print(\"The test corpus: \", test_corpus, \"\\n\")\n",
    "\n",
    "test_count3_emb, test_count_3gram = countor_vectorizer(test_corpus, ngram=3)\n",
    "print_out(test_count3_emb, test_count_3gram, ngram=\"Tri-gram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "183e4de4-ab8e-455f-9e14-c6bd3d2b2257",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TFIDF Vetorizer\n",
    "def tifdf_vectorize(data, ngram= 1, max_of_word = 100000):\n",
    "    tf_vectorizer = TfidfVectorizer(ngram_range=(ngram, ngram), max_features= max_of_word)\n",
    "    embed = tf_vectorizer.fit_transform(data).toarray()\n",
    "    print('the tifvectorize with', str(np.array(embed).shape[1]), \"features\")\n",
    "    return embed, tf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99f6c63b-d8da-454d-a362-8d89c608e50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text corpus is: ['chang deepthought think world', 'abl cho', 'inspir lif liv mirac mirac', 'alit book class hum', 'beyourself inspir']\n",
      "the tifvectorize with 15 features\n",
      "Uni-gram bag-of-words: \n",
      "['abl' 'alit' 'beyourself' 'book' 'chang' 'cho' 'class' 'deepthought'\n",
      " 'hum' 'inspir' 'lif' 'liv' 'mirac' 'think' 'world'] \n",
      "\n",
      "Uni-gram bag-of-feature: \n",
      "{'world': 38, 'cre': 8, 'process': 28, 'think': 32, 'cannot': 5, 'chang': 6, 'without': 37, 'cho': 7, 'harry': 14, 'show': 30, 'tru': 34, 'far': 10, 'abl': 0, 'two': 35, 'way': 36, 'liv': 19, 'lif': 18, 'on': 25, 'though': 33, 'noth': 23, 'mirac': 21, 'everyth': 9, 'person': 26, 'gentlem': 12, 'lady': 17, 'plea': 27, 'good': 13, 'novel': 24, 'must': 22, 'intol': 16, 'stupid': 31, 'imperfect': 15, 'beauty': 2, 'mad': 20, 'geni': 11, 'bet': 3, 'absolv': 1, 'ridic': 29, 'bor': 4} \n",
      "\n",
      "BoW matrix:\n",
      "              0         1    2    3         4\n",
      "abl         0.0  0.707107  0.0  0.0  0.000000\n",
      "alit        0.0  0.000000  0.0  0.5  0.000000\n",
      "beyourself  0.0  0.000000  0.0  0.0  0.778283\n",
      "book        0.0  0.000000  0.0  0.5  0.000000\n",
      "chang       0.5  0.000000  0.0  0.0  0.000000 \n",
      "\n",
      "Uni-gram vector example:\n",
      "world cre process think cannot chang without chang think\n",
      "[0.  0.  0.  0.  0.5 0.  0.  0.5 0.  0.  0.  0.  0.  0.5 0.5] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_corpus = df['Tags'][:5].tolist()\n",
    "print(f\"The text corpus is: {text_corpus}\")\n",
    "\n",
    "tff1_emb, tff1_gram = tifdf_vectorize(text_corpus, ngram=1)\n",
    "print_out(tff1_emb, tff1_gram, ngram = 'Uni-gram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b07e255-2e3f-42a6-af92-e90cfcbffe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tifvectorize with 12 features\n",
      "bi_gram bag-of-words: \n",
      "['abl cho' 'alit book' 'beyourself inspir' 'book class'\n",
      " 'chang deepthought' 'class hum' 'deepthought think' 'inspir lif'\n",
      " 'lif liv' 'liv mirac' 'mirac mirac' 'think world'] \n",
      "\n",
      "bi_gram bag-of-feature: \n",
      "{'world': 38, 'cre': 8, 'process': 28, 'think': 32, 'cannot': 5, 'chang': 6, 'without': 37, 'cho': 7, 'harry': 14, 'show': 30, 'tru': 34, 'far': 10, 'abl': 0, 'two': 35, 'way': 36, 'liv': 19, 'lif': 18, 'on': 25, 'though': 33, 'noth': 23, 'mirac': 21, 'everyth': 9, 'person': 26, 'gentlem': 12, 'lady': 17, 'plea': 27, 'good': 13, 'novel': 24, 'must': 22, 'intol': 16, 'stupid': 31, 'imperfect': 15, 'beauty': 2, 'mad': 20, 'geni': 11, 'bet': 3, 'absolv': 1, 'ridic': 29, 'bor': 4} \n",
      "\n",
      "BoW matrix:\n",
      "                         0    1    2        3    4\n",
      "abl cho            0.00000  1.0  0.0  0.00000  0.0\n",
      "alit book          0.00000  0.0  0.0  0.57735  0.0\n",
      "beyourself inspir  0.00000  0.0  0.0  0.00000  1.0\n",
      "book class         0.00000  0.0  0.0  0.57735  0.0\n",
      "chang deepthought  0.57735  0.0  0.0  0.00000  0.0 \n",
      "\n",
      "bi_gram vector example:\n",
      "world cre process think cannot chang without chang think\n",
      "[0.         0.         0.         0.         0.57735027 0.\n",
      " 0.57735027 0.         0.         0.         0.         0.57735027] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tff2_emb, tff2_gram = tifdf_vectorize(text_corpus, ngram=2)\n",
    "print_out(tff2_emb, tff2_gram, ngram = 'bi_gram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f8c913-0f37-48b3-a4cb-e9858726f2f7",
   "metadata": {},
   "source": [
    "BASIC WORD EMBEDDINGS METHODS\n",
    "\n",
    "\n",
    "### WORD2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcaeba35-fe15-48bb-8ba1-6865d2c5e256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 10.3 µs\n",
      "gensim version : 4.3.3\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "import gensim\n",
    "\n",
    "print(\"gensim version :\", gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e0076ca-d5a6-4470-8ffd-f5d3aca3716d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da819809-8f7e-4662-ba20-69bed04f2716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef3d2d-a521-44bd-b3e4-c9d6f5f897b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edadf2bf-601e-4af5-a46e-eb597425a0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b1aa1f-4614-468c-aabf-6f0be90215b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91172cb-6249-448b-8b5e-5f1e7e811a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288c5bb7-e984-484d-8c9d-373e5c7cc38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1063f1-77b2-4c41-bb74-57ca78db2d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd55605-80f5-4134-bccc-3718b49b6d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9141fd80-37a0-4e78-bfca-a265c8524be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679a1cf5-a063-4222-83ca-f1753150434b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f96a1c-9513-48ff-b48e-c2c727af1efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f3f7cd-fff8-4a8b-9d98-bed35d05f9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe4c56-cc0a-46ae-922f-552209b62f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360ff99-3726-40a7-a848-adce409edbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
